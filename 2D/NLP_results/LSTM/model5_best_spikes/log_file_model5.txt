GPUs:  10
Epochs: 50
seqlen:100
dropout:0.5
======================================================

FOLD =  0 :
======================================================
preparing data...
Training word2vec for 600 epochs...
word2vec best epoch: 535, loss: 33394.0
Fold 0 (prep data) done in: 1.299 minutes (0.022 hours)
After sliding window: ((6778, 100, 125), (6778, 2))
After sliding window: ((0, 100, 125), (0, 2))
Model: "RatLSTM"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Input (InputLayer)           [(None, 100, 125)]        0         
_________________________________________________________________
firstLstmBlock (LSTM)        (None, 100, 512)          1306624   
_________________________________________________________________
firstLstmDropout (Dropout)   (None, 100, 512)          0         
_________________________________________________________________
secondLstmBlock (LSTM)       (None, 512)               2099200   
_________________________________________________________________
secondLstmDropout (Dropout)  (None, 512)               0         
_________________________________________________________________
Output (Dense)               (None, 2)                 1026      
=================================================================
Total params: 3,406,850
Trainable params: 3,406,850
Non-trainable params: 0
_________________________________________________________________
None
(6778, 100, 125)
(6778, 2)
(0, 100, 125)
(0, 2)
Epoch 1/50
106/106 - 52s - loss: 1602.5869
Epoch 2/50
106/106 - 51s - loss: 769.1672
Epoch 3/50
106/106 - 52s - loss: 487.3953
Epoch 4/50
106/106 - 51s - loss: 361.3250
Epoch 5/50
106/106 - 51s - loss: 234.1808
Epoch 6/50
106/106 - 51s - loss: 178.0281
Epoch 7/50
106/106 - 51s - loss: 145.4741
Epoch 8/50
106/106 - 51s - loss: 113.0143
Epoch 9/50
106/106 - 51s - loss: 133.4848
Epoch 10/50
106/106 - 51s - loss: 93.5826
Epoch 11/50
106/106 - 51s - loss: 84.2693
Epoch 12/50
106/106 - 51s - loss: 74.2816
Epoch 13/50
106/106 - 51s - loss: 72.1225
Epoch 14/50
106/106 - 51s - loss: 66.4689
Epoch 15/50
106/106 - 51s - loss: 62.1681
Epoch 16/50
106/106 - 51s - loss: 62.4097
Epoch 17/50
106/106 - 51s - loss: 57.6036
Epoch 18/50
106/106 - 51s - loss: 54.4307
Epoch 19/50
106/106 - 51s - loss: 52.5866
Epoch 20/50
106/106 - 51s - loss: 52.2540
Epoch 21/50
106/106 - 51s - loss: 49.0449
Epoch 22/50
106/106 - 51s - loss: 47.0056
Epoch 23/50
106/106 - 51s - loss: 44.8224
Epoch 24/50
106/106 - 51s - loss: 43.7593
Epoch 25/50
106/106 - 51s - loss: 44.3874
Epoch 26/50
106/106 - 51s - loss: 42.2649
Epoch 27/50
106/106 - 51s - loss: 41.9161
Epoch 28/50
106/106 - 51s - loss: 41.1852
Epoch 29/50
106/106 - 51s - loss: 39.4873
Epoch 30/50
106/106 - 51s - loss: 40.8753
Epoch 31/50
106/106 - 51s - loss: 37.7915
Epoch 32/50
106/106 - 51s - loss: 36.9016
Epoch 33/50
106/106 - 51s - loss: 36.7037
Epoch 34/50
106/106 - 51s - loss: 35.5665
Epoch 35/50
106/106 - 51s - loss: 36.5258
Epoch 36/50
106/106 - 51s - loss: 33.9191
Epoch 37/50
106/106 - 51s - loss: 34.5886
Epoch 38/50
106/106 - 51s - loss: 33.5902
Epoch 39/50
106/106 - 51s - loss: 32.8484
Epoch 40/50
106/106 - 51s - loss: 34.7912
Epoch 41/50
106/106 - 51s - loss: 31.9856
Epoch 42/50
106/106 - 51s - loss: 32.5899
Epoch 43/50
106/106 - 51s - loss: 32.8501
Epoch 44/50
106/106 - 51s - loss: 30.6841
Epoch 45/50
106/106 - 51s - loss: 32.0330
Epoch 46/50
106/106 - 51s - loss: 30.8940
Epoch 47/50
106/106 - 51s - loss: 31.5970
Epoch 48/50
106/106 - 51s - loss: 29.8141
Epoch 49/50
106/106 - 51s - loss: 30.1116
Epoch 50/50
106/106 - 51s - loss: 30.5412
After sliding window: ((673, 100, 125), (673, 2))
After sliding window: ((6848, 100, 125), (6848, 2))

Errors of models with sentences (fold= 0 ):
mean: test:  16.153241721817352 train: 4.665755791785377
median: test:  11.623803955246817 train: 4.086775978940689
Fold 0 (sents) done in: 43.503 minutes (0.725 hours)
-------------------------------------------

After sliding window: ((6778, 100, 63), (6778, 2))
After sliding window: ((0, 100, 63), (0, 2))
Model: "RatLSTM"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Input (InputLayer)           [(None, 100, 63)]         0         
_________________________________________________________________
firstLstmBlock (LSTM)        (None, 100, 512)          1179648   
_________________________________________________________________
firstLstmDropout (Dropout)   (None, 100, 512)          0         
_________________________________________________________________
secondLstmBlock (LSTM)       (None, 512)               2099200   
_________________________________________________________________
secondLstmDropout (Dropout)  (None, 512)               0         
_________________________________________________________________
Output (Dense)               (None, 2)                 1026      
=================================================================
Total params: 3,279,874
Trainable params: 3,279,874
Non-trainable params: 0
_________________________________________________________________
None
(6778, 100, 63)
(6778, 2)
(0, 100, 63)
(0, 2)
Epoch 1/50
106/106 - 51s - loss: 1510.8425
Epoch 2/50
106/106 - 51s - loss: 844.7509
Epoch 3/50
106/106 - 51s - loss: 814.4916
Epoch 4/50
106/106 - 51s - loss: 821.5876
Epoch 5/50
106/106 - 51s - loss: 818.2227
Epoch 6/50
106/106 - 51s - loss: 626.2532
Epoch 7/50
106/106 - 51s - loss: 576.3987
Epoch 8/50
106/106 - 51s - loss: 543.5970
Epoch 9/50
106/106 - 51s - loss: 439.5970
Epoch 10/50
106/106 - 51s - loss: 328.6877
Epoch 11/50
106/106 - 51s - loss: 247.1737
Epoch 12/50
106/106 - 51s - loss: 192.3546
Epoch 13/50
106/106 - 51s - loss: 148.9173
Epoch 14/50
106/106 - 51s - loss: 122.9561
Epoch 15/50
106/106 - 51s - loss: 97.6604
Epoch 16/50
106/106 - 51s - loss: 95.0691
Epoch 17/50
106/106 - 51s - loss: 79.2364
Epoch 18/50
106/106 - 51s - loss: 80.7991
Epoch 19/50
106/106 - 51s - loss: 66.7061
Epoch 20/50
106/106 - 51s - loss: 63.9465
Epoch 21/50
106/106 - 51s - loss: 59.9553
Epoch 22/50
106/106 - 51s - loss: 62.4860
Epoch 23/50
106/106 - 51s - loss: 54.8887
Epoch 24/50
106/106 - 51s - loss: 54.7751
Epoch 25/50
106/106 - 51s - loss: 54.5057
Epoch 26/50
106/106 - 51s - loss: 48.6216
Epoch 27/50
106/106 - 51s - loss: 47.7442
Epoch 28/50
106/106 - 51s - loss: 43.5239
Epoch 29/50
106/106 - 51s - loss: 54.2966
Epoch 30/50
106/106 - 51s - loss: 40.4532
Epoch 31/50
106/106 - 51s - loss: 41.1639
Epoch 32/50
106/106 - 51s - loss: 39.9611
Epoch 33/50
106/106 - 51s - loss: 38.9946
Epoch 34/50
106/106 - 51s - loss: 39.7994
Epoch 35/50
106/106 - 51s - loss: 37.3720
Epoch 36/50
106/106 - 51s - loss: 37.2347
Epoch 37/50
106/106 - 51s - loss: 36.9811
Epoch 38/50
106/106 - 51s - loss: 36.0217
Epoch 39/50
106/106 - 51s - loss: 35.0581
Epoch 40/50
106/106 - 51s - loss: 34.0932
Epoch 41/50
106/106 - 51s - loss: 34.5691
Epoch 42/50
106/106 - 51s - loss: 32.6238
Epoch 43/50
106/106 - 51s - loss: 33.0029
Epoch 44/50
106/106 - 51s - loss: 32.8145
Epoch 45/50
106/106 - 51s - loss: 30.8982
Epoch 46/50
106/106 - 51s - loss: 31.8271
Epoch 47/50
106/106 - 51s - loss: 31.6862
Epoch 48/50
106/106 - 51s - loss: 32.0269
Epoch 49/50
106/106 - 51s - loss: 29.8986
Epoch 50/50
106/106 - 51s - loss: 29.5889
After sliding window: ((673, 100, 63), (673, 2))
After sliding window: ((6848, 100, 63), (6848, 2))

Errors of models with spikes (fold= 0 ):
mean: test:  13.244795332280395 train: 4.588253160497204
median: test:  10.550507869847111 train: 4.127368238310131
Fold 0 (spikes) done in: 43.503 minutes (0.725 hours)
======================================================

FOLD =  1 :
======================================================
preparing data...
Training word2vec for 600 epochs...
word2vec best epoch: 555, loss: 32592.0
Fold 1 (prep data) done in: 1.198 minutes (0.02 hours)
After sliding window: ((6779, 100, 125), (6779, 2))
After sliding window: ((0, 100, 125), (0, 2))
Model: "RatLSTM"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Input (InputLayer)           [(None, 100, 125)]        0         
_________________________________________________________________
firstLstmBlock (LSTM)        (None, 100, 512)          1306624   
_________________________________________________________________
firstLstmDropout (Dropout)   (None, 100, 512)          0         
_________________________________________________________________
secondLstmBlock (LSTM)       (None, 512)               2099200   
_________________________________________________________________
secondLstmDropout (Dropout)  (None, 512)               0         
_________________________________________________________________
Output (Dense)               (None, 2)                 1026      
=================================================================
Total params: 3,406,850
Trainable params: 3,406,850
Non-trainable params: 0
_________________________________________________________________
None
(6779, 100, 125)
(6779, 2)
(0, 100, 125)
(0, 2)
Epoch 1/50
106/106 - 51s - loss: 1428.8011
Epoch 2/50
106/106 - 51s - loss: 766.8215
Epoch 3/50
106/106 - 51s - loss: 529.7098
Epoch 4/50
106/106 - 51s - loss: 313.7523
Epoch 5/50
106/106 - 50s - loss: 221.6076
Epoch 6/50
106/106 - 51s - loss: 163.1759
Epoch 7/50
106/106 - 50s - loss: 131.7657
Epoch 8/50
106/106 - 50s - loss: 116.0872
Epoch 9/50
106/106 - 50s - loss: 99.8485
Epoch 10/50
106/106 - 50s - loss: 91.0809
Epoch 11/50
106/106 - 50s - loss: 80.5059
Epoch 12/50
106/106 - 50s - loss: 72.8178
Epoch 13/50
106/106 - 50s - loss: 69.8757
Epoch 14/50
106/106 - 50s - loss: 64.6660
Epoch 15/50
106/106 - 51s - loss: 64.1753
Epoch 16/50
106/106 - 51s - loss: 57.2401
Epoch 17/50
106/106 - 51s - loss: 54.8625
Epoch 18/50
106/106 - 50s - loss: 52.0595
Epoch 19/50
106/106 - 51s - loss: 52.0497
Epoch 20/50
106/106 - 50s - loss: 50.7641
Epoch 21/50
106/106 - 50s - loss: 47.0774
Epoch 22/50
106/106 - 51s - loss: 46.8686
Epoch 23/50
106/106 - 51s - loss: 47.6941
Epoch 24/50
106/106 - 50s - loss: 44.0628
Epoch 25/50
106/106 - 51s - loss: 40.2766
Epoch 26/50
106/106 - 51s - loss: 40.8387
Epoch 27/50
106/106 - 51s - loss: 50.2950
Epoch 28/50
106/106 - 51s - loss: 40.9008
Epoch 29/50
106/106 - 51s - loss: 38.0493
Epoch 30/50
106/106 - 50s - loss: 38.1596
Epoch 31/50
106/106 - 51s - loss: 37.7165
Epoch 32/50
106/106 - 50s - loss: 36.6971
Epoch 33/50
106/106 - 51s - loss: 44.0413
Epoch 34/50
106/106 - 50s - loss: 34.8991
Epoch 35/50
106/106 - 51s - loss: 35.1877
Epoch 36/50
106/106 - 51s - loss: 35.3869
Epoch 37/50
106/106 - 51s - loss: 33.8535
Epoch 38/50
106/106 - 51s - loss: 33.3781
Epoch 39/50
106/106 - 50s - loss: 33.2193
Epoch 40/50
106/106 - 51s - loss: 32.2061
Epoch 41/50
106/106 - 50s - loss: 31.9641
Epoch 42/50
106/106 - 50s - loss: 32.8638
Epoch 43/50
106/106 - 51s - loss: 31.3165
Epoch 44/50
106/106 - 51s - loss: 31.6829
Epoch 45/50
106/106 - 50s - loss: 32.1068
Epoch 46/50
106/106 - 51s - loss: 30.8499
Epoch 47/50
106/106 - 51s - loss: 30.7996
Epoch 48/50
106/106 - 51s - loss: 31.0258
Epoch 49/50
106/106 - 51s - loss: 28.8208
Epoch 50/50
106/106 - 51s - loss: 29.8282
After sliding window: ((672, 100, 125), (672, 2))
After sliding window: ((6849, 100, 125), (6849, 2))

Errors of models with sentences (fold= 1 ):
mean: test:  14.329326025434066 train: 4.118065983286923
median: test:  11.334338685304143 train: 3.552522817437699
Fold 1 (sents) done in: 43.12 minutes (0.719 hours)
-------------------------------------------

After sliding window: ((6779, 100, 63), (6779, 2))
After sliding window: ((0, 100, 63), (0, 2))
Model: "RatLSTM"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Input (InputLayer)           [(None, 100, 63)]         0         
_________________________________________________________________
firstLstmBlock (LSTM)        (None, 100, 512)          1179648   
_________________________________________________________________
firstLstmDropout (Dropout)   (None, 100, 512)          0         
_________________________________________________________________
secondLstmBlock (LSTM)       (None, 512)               2099200   
_________________________________________________________________
secondLstmDropout (Dropout)  (None, 512)               0         
_________________________________________________________________
Output (Dense)               (None, 2)                 1026      
=================================================================
Total params: 3,279,874
Trainable params: 3,279,874
Non-trainable params: 0
_________________________________________________________________
None
(6779, 100, 63)
(6779, 2)
(0, 100, 63)
(0, 2)
Epoch 1/50
106/106 - 50s - loss: 1448.1198
Epoch 2/50
106/106 - 50s - loss: 934.4473
Epoch 3/50
106/106 - 50s - loss: 774.9987
Epoch 4/50
106/106 - 50s - loss: 803.9345
Epoch 5/50
106/106 - 50s - loss: 687.7828
Epoch 6/50
106/106 - 50s - loss: 551.2724
Epoch 7/50
106/106 - 50s - loss: 427.5360
Epoch 8/50
106/106 - 50s - loss: 331.6031
Epoch 9/50
106/106 - 50s - loss: 243.6729
Epoch 10/50
106/106 - 50s - loss: 174.6750
Epoch 11/50
106/106 - 50s - loss: 153.7594
Epoch 12/50
106/106 - 50s - loss: 114.5507
Epoch 13/50
106/106 - 50s - loss: 101.7155
Epoch 14/50
106/106 - 50s - loss: 90.7215
Epoch 15/50
106/106 - 50s - loss: 76.9745
Epoch 16/50
106/106 - 50s - loss: 71.4771
Epoch 17/50
106/106 - 50s - loss: 65.4904
Epoch 18/50
106/106 - 50s - loss: 60.0900
Epoch 19/50
106/106 - 50s - loss: 58.4006
Epoch 20/50
106/106 - 50s - loss: 54.9349
Epoch 21/50
106/106 - 50s - loss: 53.4800
Epoch 22/50
106/106 - 50s - loss: 58.3268
Epoch 23/50
106/106 - 50s - loss: 47.5346
Epoch 24/50
106/106 - 50s - loss: 46.5285
Epoch 25/50
106/106 - 50s - loss: 53.5937
Epoch 26/50
106/106 - 50s - loss: 44.0587
Epoch 27/50
106/106 - 50s - loss: 41.8767
Epoch 28/50
106/106 - 50s - loss: 40.2761
Epoch 29/50
106/106 - 50s - loss: 40.1865
Epoch 30/50
106/106 - 50s - loss: 39.2385
Epoch 31/50
106/106 - 50s - loss: 36.6833
Epoch 32/50
106/106 - 50s - loss: 36.4713
Epoch 33/50
106/106 - 50s - loss: 36.6847
Epoch 34/50
106/106 - 50s - loss: 35.6263
Epoch 35/50
106/106 - 50s - loss: 34.9751
Epoch 36/50
106/106 - 50s - loss: 34.3839
Epoch 37/50
106/106 - 50s - loss: 38.4287
Epoch 38/50
106/106 - 50s - loss: 33.4262
Epoch 39/50
106/106 - 50s - loss: 33.2042
Epoch 40/50
106/106 - 50s - loss: 33.4274
Epoch 41/50
106/106 - 50s - loss: 31.2558
Epoch 42/50
106/106 - 50s - loss: 31.1203
Epoch 43/50
106/106 - 50s - loss: 69.3148
Epoch 44/50
106/106 - 50s - loss: 30.0959
Epoch 45/50
106/106 - 50s - loss: 28.2584
Epoch 46/50
106/106 - 50s - loss: 30.2566
Epoch 47/50
106/106 - 50s - loss: 30.5411
Epoch 48/50
106/106 - 50s - loss: 28.8961
Epoch 49/50
106/106 - 50s - loss: 28.5630
Epoch 50/50
106/106 - 50s - loss: 28.1217
After sliding window: ((672, 100, 63), (672, 2))
After sliding window: ((6849, 100, 63), (6849, 2))

Errors of models with spikes (fold= 1 ):
mean: test:  13.941028315565795 train: 4.042021858328859
median: test:  11.977064868427309 train: 3.5725155540335867
Fold 1 (spikes) done in: 42.662 minutes (0.711 hours)
======================================================

FOLD =  2 :
======================================================
preparing data...
Training word2vec for 600 epochs...
word2vec best epoch: 521, loss: 33198.0
Fold 2 (prep data) done in: 1.213 minutes (0.02 hours)
After sliding window: ((6778, 100, 125), (6778, 2))
After sliding window: ((0, 100, 125), (0, 2))
Model: "RatLSTM"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Input (InputLayer)           [(None, 100, 125)]        0         
_________________________________________________________________
firstLstmBlock (LSTM)        (None, 100, 512)          1306624   
_________________________________________________________________
firstLstmDropout (Dropout)   (None, 100, 512)          0         
_________________________________________________________________
secondLstmBlock (LSTM)       (None, 512)               2099200   
_________________________________________________________________
secondLstmDropout (Dropout)  (None, 512)               0         
_________________________________________________________________
Output (Dense)               (None, 2)                 1026      
=================================================================
Total params: 3,406,850
Trainable params: 3,406,850
Non-trainable params: 0
_________________________________________________________________
None
(6778, 100, 125)
(6778, 2)
(0, 100, 125)
(0, 2)
Epoch 1/50
106/106 - 51s - loss: 1549.4045
Epoch 2/50
106/106 - 51s - loss: 795.2999
Epoch 3/50
106/106 - 51s - loss: 722.1931
Epoch 4/50
106/106 - 51s - loss: 581.9464
Epoch 5/50
106/106 - 51s - loss: 470.2195
Epoch 6/50
106/106 - 51s - loss: 355.7456
Epoch 7/50
106/106 - 51s - loss: 257.4503
Epoch 8/50
106/106 - 51s - loss: 188.0257
Epoch 9/50
106/106 - 51s - loss: 144.0980
Epoch 10/50
106/106 - 51s - loss: 122.8422
Epoch 11/50
106/106 - 51s - loss: 103.1367
Epoch 12/50
106/106 - 51s - loss: 95.7891
Epoch 13/50
106/106 - 51s - loss: 85.2433
Epoch 14/50
106/106 - 51s - loss: 81.5500
Epoch 15/50
106/106 - 51s - loss: 75.1951
Epoch 16/50
106/106 - 51s - loss: 69.8236
Epoch 17/50
106/106 - 51s - loss: 65.4799
Epoch 18/50
106/106 - 51s - loss: 61.1638
Epoch 19/50
106/106 - 51s - loss: 60.6203
Epoch 20/50
106/106 - 51s - loss: 61.2923
Epoch 21/50
106/106 - 51s - loss: 54.0752
Epoch 22/50
106/106 - 51s - loss: 53.0690
Epoch 23/50
106/106 - 51s - loss: 50.4558
Epoch 24/50
106/106 - 50s - loss: 74.9279
Epoch 25/50
106/106 - 51s - loss: 47.7350
Epoch 26/50
106/106 - 51s - loss: 46.4068
Epoch 27/50
106/106 - 51s - loss: 45.1156
Epoch 28/50
106/106 - 51s - loss: 44.8439
Epoch 29/50
106/106 - 50s - loss: 42.4681
Epoch 30/50
106/106 - 51s - loss: 42.2996
Epoch 31/50
106/106 - 51s - loss: 41.6013
Epoch 32/50
106/106 - 51s - loss: 40.5151
Epoch 33/50
106/106 - 51s - loss: 40.2351
Epoch 34/50
106/106 - 51s - loss: 38.4281
Epoch 35/50
106/106 - 51s - loss: 37.8496
Epoch 36/50
106/106 - 51s - loss: 39.0358
Epoch 37/50
106/106 - 51s - loss: 41.1661
Epoch 38/50
106/106 - 51s - loss: 35.5871
Epoch 39/50
106/106 - 51s - loss: 36.6800
Epoch 40/50
106/106 - 51s - loss: 35.3306
Epoch 41/50
106/106 - 51s - loss: 33.9278
Epoch 42/50
106/106 - 51s - loss: 36.0560
Epoch 43/50
106/106 - 51s - loss: 34.7564
Epoch 44/50
106/106 - 51s - loss: 32.8685
Epoch 45/50
106/106 - 51s - loss: 42.6322
Epoch 46/50
106/106 - 51s - loss: 32.1822
Epoch 47/50
106/106 - 51s - loss: 30.9221
Epoch 48/50
106/106 - 51s - loss: 32.2129
Epoch 49/50
106/106 - 51s - loss: 31.5952
Epoch 50/50
106/106 - 51s - loss: 31.5597
After sliding window: ((673, 100, 125), (673, 2))
After sliding window: ((6848, 100, 125), (6848, 2))

Errors of models with sentences (fold= 2 ):
mean: test:  12.92201746257621 train: 4.5273817011247806
median: test:  10.184706969818405 train: 3.6333435188623975
Fold 2 (sents) done in: 43.383 minutes (0.723 hours)
-------------------------------------------

After sliding window: ((6778, 100, 63), (6778, 2))
After sliding window: ((0, 100, 63), (0, 2))
Model: "RatLSTM"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Input (InputLayer)           [(None, 100, 63)]         0         
_________________________________________________________________
firstLstmBlock (LSTM)        (None, 100, 512)          1179648   
_________________________________________________________________
firstLstmDropout (Dropout)   (None, 100, 512)          0         
_________________________________________________________________
secondLstmBlock (LSTM)       (None, 512)               2099200   
_________________________________________________________________
secondLstmDropout (Dropout)  (None, 512)               0         
_________________________________________________________________
Output (Dense)               (None, 2)                 1026      
=================================================================
Total params: 3,279,874
Trainable params: 3,279,874
Non-trainable params: 0
_________________________________________________________________
None
(6778, 100, 63)
(6778, 2)
(0, 100, 63)
(0, 2)
Epoch 1/50
106/106 - 51s - loss: 1427.3390
Epoch 2/50
106/106 - 51s - loss: 793.3499
Epoch 3/50
106/106 - 51s - loss: 766.7857
Epoch 4/50
106/106 - 51s - loss: 949.3683
Epoch 5/50
106/106 - 51s - loss: 674.7282
Epoch 6/50
106/106 - 51s - loss: 527.1044
Epoch 7/50
106/106 - 51s - loss: 404.1646
Epoch 8/50
106/106 - 51s - loss: 293.0690
Epoch 9/50
106/106 - 51s - loss: 222.0959
Epoch 10/50
106/106 - 51s - loss: 167.1767
Epoch 11/50
106/106 - 51s - loss: 115.5496
Epoch 12/50
106/106 - 51s - loss: 102.8598
Epoch 13/50
106/106 - 51s - loss: 83.0296
Epoch 14/50
106/106 - 51s - loss: 83.0476
Epoch 15/50
106/106 - 51s - loss: 76.4322
Epoch 16/50
106/106 - 51s - loss: 65.1619
Epoch 17/50
106/106 - 51s - loss: 78.5637
Epoch 18/50
106/106 - 51s - loss: 58.5041
Epoch 19/50
106/106 - 51s - loss: 54.2791
Epoch 20/50
106/106 - 51s - loss: 49.5788
Epoch 21/50
106/106 - 51s - loss: 59.9806
Epoch 22/50
106/106 - 51s - loss: 49.4225
Epoch 23/50
106/106 - 51s - loss: 43.6376
Epoch 24/50
106/106 - 51s - loss: 40.9574
Epoch 25/50
106/106 - 51s - loss: 56.0569
Epoch 26/50
106/106 - 51s - loss: 51.9650
Epoch 27/50
106/106 - 51s - loss: 40.4513
Epoch 28/50
106/106 - 50s - loss: 40.3544
Epoch 29/50
106/106 - 51s - loss: 39.1857
Epoch 30/50
106/106 - 51s - loss: 37.0800
Epoch 31/50
106/106 - 51s - loss: 35.6370
Epoch 32/50
106/106 - 51s - loss: 36.7431
Epoch 33/50
106/106 - 51s - loss: 34.2423
Epoch 34/50
106/106 - 51s - loss: 35.0495
Epoch 35/50
106/106 - 51s - loss: 35.3873
Epoch 36/50
106/106 - 51s - loss: 32.6289
Epoch 37/50
106/106 - 50s - loss: 32.4974
Epoch 38/50
106/106 - 50s - loss: 34.0182
Epoch 39/50
106/106 - 51s - loss: 31.7978
Epoch 40/50
106/106 - 51s - loss: 31.8877
Epoch 41/50
106/106 - 51s - loss: 30.8809
Epoch 42/50
106/106 - 51s - loss: 31.2854
Epoch 43/50
106/106 - 51s - loss: 31.4223
Epoch 44/50
106/106 - 51s - loss: 31.1305
Epoch 45/50
106/106 - 51s - loss: 30.0072
Epoch 46/50
106/106 - 51s - loss: 28.7614
Epoch 47/50
106/106 - 51s - loss: 30.0757
Epoch 48/50
106/106 - 51s - loss: 29.8428
Epoch 49/50
106/106 - 51s - loss: 28.3717
Epoch 50/50
106/106 - 51s - loss: 27.9652
After sliding window: ((673, 100, 63), (673, 2))
After sliding window: ((6848, 100, 63), (6848, 2))

Errors of models with spikes (fold= 2 ):
mean: test:  11.532164746459307 train: 4.3248189979962595
median: test:  8.868530216430853 train: 3.7913179766591636
Fold 2 (spikes) done in: 43.271 minutes (0.721 hours)
======================================================

FOLD =  3 :
======================================================
preparing data...
Training word2vec for 600 epochs...
word2vec best epoch: 570, loss: 32078.0
Fold 3 (prep data) done in: 1.178 minutes (0.02 hours)
After sliding window: ((6778, 100, 125), (6778, 2))
After sliding window: ((0, 100, 125), (0, 2))
Model: "RatLSTM"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Input (InputLayer)           [(None, 100, 125)]        0         
_________________________________________________________________
firstLstmBlock (LSTM)        (None, 100, 512)          1306624   
_________________________________________________________________
firstLstmDropout (Dropout)   (None, 100, 512)          0         
_________________________________________________________________
secondLstmBlock (LSTM)       (None, 512)               2099200   
_________________________________________________________________
secondLstmDropout (Dropout)  (None, 512)               0         
_________________________________________________________________
Output (Dense)               (None, 2)                 1026      
=================================================================
Total params: 3,406,850
Trainable params: 3,406,850
Non-trainable params: 0
_________________________________________________________________
None
(6778, 100, 125)
(6778, 2)
(0, 100, 125)
(0, 2)
Epoch 1/50
106/106 - 51s - loss: 1318.8983
Epoch 2/50
106/106 - 51s - loss: 763.3497
Epoch 3/50
106/106 - 51s - loss: 521.5292
Epoch 4/50
106/106 - 51s - loss: 347.3575
Epoch 5/50
106/106 - 51s - loss: 251.2730
Epoch 6/50
106/106 - 51s - loss: 184.4308
Epoch 7/50
106/106 - 51s - loss: 150.7938
Epoch 8/50
106/106 - 51s - loss: 114.3856
Epoch 9/50
106/106 - 51s - loss: 97.0087
Epoch 10/50
106/106 - 51s - loss: 93.8460
Epoch 11/50
106/106 - 51s - loss: 85.6373
Epoch 12/50
106/106 - 50s - loss: 76.4717
Epoch 13/50
106/106 - 51s - loss: 68.2363
Epoch 14/50
106/106 - 51s - loss: 65.5074
Epoch 15/50
106/106 - 51s - loss: 63.6583
Epoch 16/50
106/106 - 51s - loss: 58.6293
Epoch 17/50
106/106 - 51s - loss: 57.0903
Epoch 18/50
106/106 - 51s - loss: 56.5151
Epoch 19/50
106/106 - 51s - loss: 51.5847
Epoch 20/50
106/106 - 51s - loss: 51.6080
Epoch 21/50
106/106 - 51s - loss: 49.5384
Epoch 22/50
106/106 - 51s - loss: 47.7764
Epoch 23/50
106/106 - 51s - loss: 48.1315
Epoch 24/50
106/106 - 51s - loss: 43.4692
Epoch 25/50
106/106 - 51s - loss: 48.2744
Epoch 26/50
106/106 - 51s - loss: 46.2377
Epoch 27/50
106/106 - 51s - loss: 38.9629
Epoch 28/50
106/106 - 51s - loss: 39.8421
Epoch 29/50
106/106 - 51s - loss: 40.8968
Epoch 30/50
106/106 - 51s - loss: 41.6160
Epoch 31/50
106/106 - 51s - loss: 38.4838
Epoch 32/50
106/106 - 51s - loss: 36.8359
Epoch 33/50
106/106 - 51s - loss: 37.5738
Epoch 34/50
106/106 - 51s - loss: 36.4425
Epoch 35/50
106/106 - 51s - loss: 35.5336
Epoch 36/50
106/106 - 51s - loss: 34.3244
Epoch 37/50
106/106 - 50s - loss: 34.9077
Epoch 38/50
106/106 - 51s - loss: 33.3973
Epoch 39/50
106/106 - 51s - loss: 34.5291
Epoch 40/50
106/106 - 51s - loss: 33.9382
Epoch 41/50
106/106 - 51s - loss: 31.3819
Epoch 42/50
106/106 - 51s - loss: 32.6580
Epoch 43/50
106/106 - 51s - loss: 32.3091
Epoch 44/50
106/106 - 51s - loss: 31.3299
Epoch 45/50
106/106 - 51s - loss: 32.9454
Epoch 46/50
106/106 - 51s - loss: 31.8221
Epoch 47/50
106/106 - 51s - loss: 30.9662
Epoch 48/50
106/106 - 51s - loss: 30.4481
Epoch 49/50
106/106 - 51s - loss: 30.2964
Epoch 50/50
106/106 - 51s - loss: 30.4992
After sliding window: ((673, 100, 125), (673, 2))
After sliding window: ((6848, 100, 125), (6848, 2))

Errors of models with sentences (fold= 3 ):
mean: test:  14.50196607240159 train: 4.467134532665789
median: test:  12.58600423735465 train: 3.924768390415818
Fold 3 (sents) done in: 43.246 minutes (0.721 hours)
-------------------------------------------

After sliding window: ((6778, 100, 63), (6778, 2))
After sliding window: ((0, 100, 63), (0, 2))
Model: "RatLSTM"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Input (InputLayer)           [(None, 100, 63)]         0         
_________________________________________________________________
firstLstmBlock (LSTM)        (None, 100, 512)          1179648   
_________________________________________________________________
firstLstmDropout (Dropout)   (None, 100, 512)          0         
_________________________________________________________________
secondLstmBlock (LSTM)       (None, 512)               2099200   
_________________________________________________________________
secondLstmDropout (Dropout)  (None, 512)               0         
_________________________________________________________________
Output (Dense)               (None, 2)                 1026      
=================================================================
Total params: 3,279,874
Trainable params: 3,279,874
Non-trainable params: 0
_________________________________________________________________
None
(6778, 100, 63)
(6778, 2)
(0, 100, 63)
(0, 2)
Epoch 1/50
106/106 - 50s - loss: 1503.7976
Epoch 2/50
106/106 - 50s - loss: 814.4521
Epoch 3/50
106/106 - 50s - loss: 823.3445
Epoch 4/50
106/106 - 50s - loss: 816.3388
Epoch 5/50
106/106 - 50s - loss: 818.9876
Epoch 6/50
106/106 - 50s - loss: 768.7377
Epoch 7/50
106/106 - 50s - loss: 593.0039
Epoch 8/50
106/106 - 50s - loss: 507.4097
Epoch 9/50
106/106 - 50s - loss: 411.7877
Epoch 10/50
106/106 - 50s - loss: 284.1277
Epoch 11/50
106/106 - 50s - loss: 226.0741
Epoch 12/50
106/106 - 50s - loss: 182.9490
Epoch 13/50
106/106 - 50s - loss: 139.6745
Epoch 14/50
106/106 - 50s - loss: 109.4393
Epoch 15/50
106/106 - 51s - loss: 98.6957
Epoch 16/50
106/106 - 50s - loss: 77.9448
Epoch 17/50
106/106 - 50s - loss: 83.3078
Epoch 18/50
106/106 - 50s - loss: 73.2691
Epoch 19/50
106/106 - 50s - loss: 62.3499
Epoch 20/50
106/106 - 50s - loss: 64.7196
Epoch 21/50
106/106 - 50s - loss: 63.0482
Epoch 22/50
106/106 - 50s - loss: 56.0834
Epoch 23/50
106/106 - 50s - loss: 52.6366
Epoch 24/50
106/106 - 50s - loss: 50.4125
Epoch 25/50
106/106 - 50s - loss: 48.8172
Epoch 26/50
106/106 - 50s - loss: 63.7077
Epoch 27/50
106/106 - 50s - loss: 42.1443
Epoch 28/50
106/106 - 50s - loss: 43.3570
Epoch 29/50
106/106 - 50s - loss: 43.4071
Epoch 30/50
106/106 - 50s - loss: 40.7478
Epoch 31/50
106/106 - 50s - loss: 44.6080
Epoch 32/50
106/106 - 50s - loss: 39.6328
Epoch 33/50
106/106 - 50s - loss: 38.8658
Epoch 34/50
106/106 - 50s - loss: 38.4972
Epoch 35/50
106/106 - 50s - loss: 37.6625
Epoch 36/50
106/106 - 50s - loss: 37.3138
Epoch 37/50
106/106 - 50s - loss: 37.9645
Epoch 38/50
106/106 - 50s - loss: 34.1804
Epoch 39/50
106/106 - 50s - loss: 35.2527
Epoch 40/50
106/106 - 50s - loss: 34.2397
Epoch 41/50
106/106 - 50s - loss: 34.1895
Epoch 42/50
106/106 - 50s - loss: 31.7808
Epoch 43/50
106/106 - 50s - loss: 32.8605
Epoch 44/50
106/106 - 50s - loss: 33.3099
Epoch 45/50
106/106 - 50s - loss: 32.3257
Epoch 46/50
106/106 - 50s - loss: 30.5602
Epoch 47/50
106/106 - 50s - loss: 30.0725
Epoch 48/50
106/106 - 50s - loss: 30.3701
Epoch 49/50
106/106 - 50s - loss: 30.1394
Epoch 50/50
106/106 - 50s - loss: 30.5386
After sliding window: ((673, 100, 63), (673, 2))
After sliding window: ((6848, 100, 63), (6848, 2))

Errors of models with spikes (fold= 3 ):
mean: test:  13.78304526947631 train: 4.319640638365573
median: test:  12.521965724398953 train: 3.818134054301381
Fold 3 (spikes) done in: 42.637 minutes (0.711 hours)
======================================================

FOLD =  4 :
======================================================
preparing data...
Training word2vec for 600 epochs...
word2vec best epoch: 424, loss: 32470.0
Fold 4 (prep data) done in: 1.157 minutes (0.019 hours)
After sliding window: ((6778, 100, 125), (6778, 2))
After sliding window: ((0, 100, 125), (0, 2))
Model: "RatLSTM"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Input (InputLayer)           [(None, 100, 125)]        0         
_________________________________________________________________
firstLstmBlock (LSTM)        (None, 100, 512)          1306624   
_________________________________________________________________
firstLstmDropout (Dropout)   (None, 100, 512)          0         
_________________________________________________________________
secondLstmBlock (LSTM)       (None, 512)               2099200   
_________________________________________________________________
secondLstmDropout (Dropout)  (None, 512)               0         
_________________________________________________________________
Output (Dense)               (None, 2)                 1026      
=================================================================
Total params: 3,406,850
Trainable params: 3,406,850
Non-trainable params: 0
_________________________________________________________________
None
(6778, 100, 125)
(6778, 2)
(0, 100, 125)
(0, 2)
Epoch 1/50
106/106 - 50s - loss: 1243.7150
Epoch 2/50
106/106 - 50s - loss: 664.0149
Epoch 3/50
106/106 - 50s - loss: 411.5649
Epoch 4/50
106/106 - 50s - loss: 358.1216
Epoch 5/50
106/106 - 50s - loss: 233.8539
Epoch 6/50
106/106 - 50s - loss: 164.0913
Epoch 7/50
106/106 - 50s - loss: 136.5405
Epoch 8/50
106/106 - 50s - loss: 111.6524
Epoch 9/50
106/106 - 50s - loss: 95.7531
Epoch 10/50
106/106 - 50s - loss: 88.0468
Epoch 11/50
106/106 - 49s - loss: 78.7782
Epoch 12/50
106/106 - 50s - loss: 72.6601
Epoch 13/50
106/106 - 50s - loss: 67.6855
Epoch 14/50
106/106 - 50s - loss: 64.0629
Epoch 15/50
106/106 - 50s - loss: 61.4772
Epoch 16/50
106/106 - 50s - loss: 58.2254
Epoch 17/50
106/106 - 49s - loss: 53.6568
Epoch 18/50
106/106 - 50s - loss: 50.5662
Epoch 19/50
106/106 - 49s - loss: 61.8040
Epoch 20/50
106/106 - 50s - loss: 48.6610
Epoch 21/50
106/106 - 50s - loss: 45.7049
Epoch 22/50
106/106 - 50s - loss: 45.9585
Epoch 23/50
106/106 - 50s - loss: 47.6820
Epoch 24/50
106/106 - 50s - loss: 46.1697
Epoch 25/50
106/106 - 50s - loss: 43.2018
Epoch 26/50
106/106 - 50s - loss: 41.8065
Epoch 27/50
106/106 - 50s - loss: 39.6542
Epoch 28/50
106/106 - 50s - loss: 39.8097
Epoch 29/50
106/106 - 49s - loss: 39.6365
Epoch 30/50
106/106 - 50s - loss: 37.8914
Epoch 31/50
106/106 - 50s - loss: 36.6983
Epoch 32/50
106/106 - 50s - loss: 36.7352
Epoch 33/50
106/106 - 50s - loss: 36.2769
Epoch 34/50
106/106 - 50s - loss: 36.2974
Epoch 35/50
106/106 - 50s - loss: 36.3467
Epoch 36/50
106/106 - 50s - loss: 34.9862
Epoch 37/50
106/106 - 50s - loss: 35.1021
Epoch 38/50
106/106 - 50s - loss: 33.9460
Epoch 39/50
106/106 - 50s - loss: 34.7001
Epoch 40/50
106/106 - 50s - loss: 32.8565
Epoch 41/50
106/106 - 50s - loss: 32.3390
Epoch 42/50
106/106 - 51s - loss: 32.5010
Epoch 43/50
106/106 - 50s - loss: 31.3924
Epoch 44/50
106/106 - 50s - loss: 31.9252
Epoch 45/50
106/106 - 50s - loss: 30.9870
Epoch 46/50
106/106 - 50s - loss: 30.7130
Epoch 47/50
106/106 - 50s - loss: 30.7739
Epoch 48/50
106/106 - 50s - loss: 29.9306
Epoch 49/50
106/106 - 50s - loss: 30.3496
Epoch 50/50
106/106 - 51s - loss: 31.0332
After sliding window: ((673, 100, 125), (673, 2))
After sliding window: ((6848, 100, 125), (6848, 2))

Errors of models with sentences (fold= 4 ):
mean: test:  12.412447043672934 train: 4.778537768686053
median: test:  10.166088974323676 train: 4.2710157366334
Fold 4 (sents) done in: 42.499 minutes (0.708 hours)
-------------------------------------------

After sliding window: ((6778, 100, 63), (6778, 2))
After sliding window: ((0, 100, 63), (0, 2))
Model: "RatLSTM"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Input (InputLayer)           [(None, 100, 63)]         0         
_________________________________________________________________
firstLstmBlock (LSTM)        (None, 100, 512)          1179648   
_________________________________________________________________
firstLstmDropout (Dropout)   (None, 100, 512)          0         
_________________________________________________________________
secondLstmBlock (LSTM)       (None, 512)               2099200   
_________________________________________________________________
secondLstmDropout (Dropout)  (None, 512)               0         
_________________________________________________________________
Output (Dense)               (None, 2)                 1026      
=================================================================
Total params: 3,279,874
Trainable params: 3,279,874
Non-trainable params: 0
_________________________________________________________________
None
(6778, 100, 63)
(6778, 2)
(0, 100, 63)
(0, 2)
Epoch 1/50
106/106 - 49s - loss: 1503.0571
Epoch 2/50
106/106 - 50s - loss: 822.3137
Epoch 3/50
106/106 - 50s - loss: 819.3781
Epoch 4/50
106/106 - 50s - loss: 787.1727
Epoch 5/50
106/106 - 50s - loss: 642.5676
Epoch 6/50
106/106 - 50s - loss: 618.2661
Epoch 7/50
106/106 - 49s - loss: 378.0038
Epoch 8/50
106/106 - 50s - loss: 265.5443
Epoch 9/50
106/106 - 49s - loss: 209.0576
Epoch 10/50
106/106 - 50s - loss: 154.8305
Epoch 11/50
106/106 - 49s - loss: 120.3728
Epoch 12/50
106/106 - 49s - loss: 96.4242
Epoch 13/50
106/106 - 50s - loss: 91.9631
Epoch 14/50
106/106 - 50s - loss: 96.3370
Epoch 15/50
106/106 - 50s - loss: 74.6650
Epoch 16/50
106/106 - 49s - loss: 79.3403
Epoch 17/50
106/106 - 50s - loss: 72.6165
Epoch 18/50
106/106 - 50s - loss: 60.2684
Epoch 19/50
106/106 - 50s - loss: 54.8382
Epoch 20/50
106/106 - 49s - loss: 62.9801
Epoch 21/50
106/106 - 50s - loss: 51.2496
Epoch 22/50
106/106 - 50s - loss: 49.2709
Epoch 23/50
106/106 - 49s - loss: 47.6689
Epoch 24/50
106/106 - 49s - loss: 45.2180
Epoch 25/50
106/106 - 50s - loss: 44.2856
Epoch 26/50
106/106 - 50s - loss: 40.8234
Epoch 27/50
106/106 - 50s - loss: 43.7979
Epoch 28/50
106/106 - 50s - loss: 41.4207
Epoch 29/50
106/106 - 50s - loss: 38.4949
Epoch 30/50
106/106 - 49s - loss: 37.6001
Epoch 31/50
106/106 - 50s - loss: 36.6190
Epoch 32/50
106/106 - 50s - loss: 36.6682
Epoch 33/50
106/106 - 49s - loss: 36.0357
Epoch 34/50
106/106 - 50s - loss: 35.5029
Epoch 35/50
106/106 - 49s - loss: 40.5550
Epoch 36/50
106/106 - 50s - loss: 38.4369
Epoch 37/50
106/106 - 50s - loss: 33.0091
Epoch 38/50
106/106 - 50s - loss: 32.7674
Epoch 39/50
106/106 - 50s - loss: 43.0466
Epoch 40/50
106/106 - 50s - loss: 32.4209
Epoch 41/50
106/106 - 50s - loss: 34.6707
Epoch 42/50
106/106 - 50s - loss: 31.2699
Epoch 43/50
106/106 - 50s - loss: 30.1000
Epoch 44/50
106/106 - 50s - loss: 29.8535
Epoch 45/50
106/106 - 50s - loss: 29.8491
Epoch 46/50
106/106 - 50s - loss: 29.5206
Epoch 47/50
106/106 - 49s - loss: 31.4674
Epoch 48/50
106/106 - 50s - loss: 28.1991
Epoch 49/50
106/106 - 50s - loss: 30.0718
Epoch 50/50
106/106 - 49s - loss: 27.3435
After sliding window: ((673, 100, 63), (673, 2))
After sliding window: ((6848, 100, 63), (6848, 2))

Errors of models with spikes (fold= 4 ):
mean: test:  10.349394853516245 train: 3.5734609642993376
median: test:  8.5608873618267 train: 3.203196387722575
Fold 4 (spikes) done in: 42.283 minutes (0.705 hours)
======================================================

FOLD =  5 :
======================================================
preparing data...
Training word2vec for 600 epochs...
word2vec best epoch: 441, loss: 33730.0
Fold 5 (prep data) done in: 1.59 minutes (0.026 hours)
After sliding window: ((6778, 100, 125), (6778, 2))
After sliding window: ((0, 100, 125), (0, 2))
Model: "RatLSTM"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Input (InputLayer)           [(None, 100, 125)]        0         
_________________________________________________________________
firstLstmBlock (LSTM)        (None, 100, 512)          1306624   
_________________________________________________________________
firstLstmDropout (Dropout)   (None, 100, 512)          0         
_________________________________________________________________
secondLstmBlock (LSTM)       (None, 512)               2099200   
_________________________________________________________________
secondLstmDropout (Dropout)  (None, 512)               0         
_________________________________________________________________
Output (Dense)               (None, 2)                 1026      
=================================================================
Total params: 3,406,850
Trainable params: 3,406,850
Non-trainable params: 0
_________________________________________________________________
None
(6778, 100, 125)
(6778, 2)
(0, 100, 125)
(0, 2)
Epoch 1/50
106/106 - 51s - loss: 1457.7106
Epoch 2/50
106/106 - 49s - loss: 827.9087
Epoch 3/50
106/106 - 49s - loss: 533.9545
Epoch 4/50
106/106 - 49s - loss: 392.8580
Epoch 5/50
106/106 - 49s - loss: 251.9729
Epoch 6/50
106/106 - 49s - loss: 220.9904
Epoch 7/50
106/106 - 50s - loss: 147.1306
Epoch 8/50
106/106 - 50s - loss: 135.8894
Epoch 9/50
106/106 - 49s - loss: 99.4666
Epoch 10/50
106/106 - 49s - loss: 89.3768
Epoch 11/50
106/106 - 50s - loss: 81.1881
Epoch 12/50
106/106 - 49s - loss: 73.1750
Epoch 13/50
106/106 - 50s - loss: 71.3844
Epoch 14/50
106/106 - 49s - loss: 66.1431
Epoch 15/50
106/106 - 49s - loss: 60.5949
Epoch 16/50
106/106 - 49s - loss: 68.3283
Epoch 17/50
106/106 - 49s - loss: 54.7236
Epoch 18/50
106/106 - 49s - loss: 54.3693
Epoch 19/50
106/106 - 49s - loss: 49.4762
Epoch 20/50
106/106 - 49s - loss: 49.3980
Epoch 21/50
106/106 - 49s - loss: 48.7471
Epoch 22/50
106/106 - 49s - loss: 46.2454
Epoch 23/50
106/106 - 49s - loss: 46.6700
Epoch 24/50
106/106 - 49s - loss: 41.9748
Epoch 25/50
106/106 - 49s - loss: 43.8166
Epoch 26/50
106/106 - 49s - loss: 46.5350
Epoch 27/50
106/106 - 49s - loss: 41.1550
Epoch 28/50
106/106 - 49s - loss: 39.2796
Epoch 29/50
106/106 - 49s - loss: 39.6173
Epoch 30/50
106/106 - 49s - loss: 37.7926
Epoch 31/50
106/106 - 49s - loss: 38.4184
Epoch 32/50
106/106 - 49s - loss: 37.5114
Epoch 33/50
106/106 - 49s - loss: 37.4467
Epoch 34/50
106/106 - 49s - loss: 35.5636
Epoch 35/50
106/106 - 49s - loss: 34.4673
Epoch 36/50
106/106 - 49s - loss: 36.6937
Epoch 37/50
106/106 - 49s - loss: 34.7274
Epoch 38/50
106/106 - 49s - loss: 34.2723
Epoch 39/50
106/106 - 49s - loss: 34.7959
Epoch 40/50
106/106 - 49s - loss: 32.2360
Epoch 41/50
106/106 - 50s - loss: 33.7589
Epoch 42/50
106/106 - 49s - loss: 32.1071
Epoch 43/50
106/106 - 49s - loss: 33.8541
Epoch 44/50
106/106 - 50s - loss: 31.4518
Epoch 45/50
106/106 - 49s - loss: 31.5414
Epoch 46/50
106/106 - 49s - loss: 31.2477
Epoch 47/50
106/106 - 50s - loss: 30.0604
Epoch 48/50
106/106 - 49s - loss: 30.7543
Epoch 49/50
106/106 - 50s - loss: 29.7630
Epoch 50/50
106/106 - 50s - loss: 29.5803
After sliding window: ((673, 100, 125), (673, 2))
After sliding window: ((6848, 100, 125), (6848, 2))

Errors of models with sentences (fold= 5 ):
mean: test:  11.276448479700123 train: 4.3076361398149725
median: test:  9.239064698416511 train: 3.7787133410297464
Fold 5 (sents) done in: 42.117 minutes (0.702 hours)
-------------------------------------------

After sliding window: ((6778, 100, 63), (6778, 2))
After sliding window: ((0, 100, 63), (0, 2))
Model: "RatLSTM"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Input (InputLayer)           [(None, 100, 63)]         0         
_________________________________________________________________
firstLstmBlock (LSTM)        (None, 100, 512)          1179648   
_________________________________________________________________
firstLstmDropout (Dropout)   (None, 100, 512)          0         
_________________________________________________________________
secondLstmBlock (LSTM)       (None, 512)               2099200   
_________________________________________________________________
secondLstmDropout (Dropout)  (None, 512)               0         
_________________________________________________________________
Output (Dense)               (None, 2)                 1026      
=================================================================
Total params: 3,279,874
Trainable params: 3,279,874
Non-trainable params: 0
_________________________________________________________________
None
(6778, 100, 63)
(6778, 2)
(0, 100, 63)
(0, 2)
Epoch 1/50
106/106 - 50s - loss: 1419.6111
Epoch 2/50
106/106 - 49s - loss: 785.1351
Epoch 3/50
106/106 - 50s - loss: 773.8670
Epoch 4/50
106/106 - 49s - loss: 777.9653
Epoch 5/50
106/106 - 50s - loss: 583.4047
Epoch 6/50
106/106 - 50s - loss: 447.4355
Epoch 7/50
106/106 - 50s - loss: 324.6712
Epoch 8/50
106/106 - 50s - loss: 245.6346
Epoch 9/50
106/106 - 50s - loss: 204.7353
Epoch 10/50
106/106 - 49s - loss: 222.2932
Epoch 11/50
106/106 - 50s - loss: 159.8416
Epoch 12/50
106/106 - 50s - loss: 109.1199
Epoch 13/50
106/106 - 50s - loss: 86.2574
Epoch 14/50
106/106 - 50s - loss: 90.9858
Epoch 15/50
106/106 - 50s - loss: 76.6192
Epoch 16/50
106/106 - 50s - loss: 73.4715
Epoch 17/50
106/106 - 50s - loss: 69.3857
Epoch 18/50
106/106 - 50s - loss: 62.2810
Epoch 19/50
106/106 - 50s - loss: 63.8739
Epoch 20/50
106/106 - 50s - loss: 56.4897
Epoch 21/50
106/106 - 50s - loss: 53.0088
Epoch 22/50
106/106 - 50s - loss: 52.5214
Epoch 23/50
106/106 - 50s - loss: 47.8071
Epoch 24/50
106/106 - 50s - loss: 45.3881
Epoch 25/50
106/106 - 50s - loss: 46.0898
Epoch 26/50
106/106 - 50s - loss: 41.9747
Epoch 27/50
106/106 - 50s - loss: 44.3964
Epoch 28/50
106/106 - 50s - loss: 42.0549
Epoch 29/50
106/106 - 50s - loss: 40.6408
Epoch 30/50
106/106 - 50s - loss: 48.2418
Epoch 31/50
106/106 - 50s - loss: 38.4155
Epoch 32/50
106/106 - 50s - loss: 37.8859
Epoch 33/50
106/106 - 50s - loss: 40.4601
Epoch 34/50
106/106 - 50s - loss: 53.1553
Epoch 35/50
106/106 - 50s - loss: 38.1000
Epoch 36/50
106/106 - 50s - loss: 35.3279
Epoch 37/50
106/106 - 50s - loss: 34.2946
Epoch 38/50
106/106 - 50s - loss: 35.7322
Epoch 39/50
106/106 - 50s - loss: 33.7385
Epoch 40/50
106/106 - 50s - loss: 32.3704
Epoch 41/50
106/106 - 50s - loss: 33.2511
Epoch 42/50
106/106 - 50s - loss: 31.8486
Epoch 43/50
106/106 - 50s - loss: 32.0548
Epoch 44/50
106/106 - 50s - loss: 31.6242
Epoch 45/50
106/106 - 49s - loss: 30.7846
Epoch 46/50
106/106 - 50s - loss: 31.6304
Epoch 47/50
106/106 - 50s - loss: 31.0490
Epoch 48/50
106/106 - 50s - loss: 29.9540
Epoch 49/50
106/106 - 50s - loss: 29.3781
Epoch 50/50
106/106 - 50s - loss: 30.0965
After sliding window: ((673, 100, 63), (673, 2))
After sliding window: ((6848, 100, 63), (6848, 2))

Errors of models with spikes (fold= 5 ):
mean: test:  11.693117128325829 train: 4.414337713342877
median: test:  9.522757020311241 train: 4.01655702500458
Fold 5 (spikes) done in: 42.443 minutes (0.707 hours)
======================================================

FOLD =  6 :
======================================================
preparing data...
Training word2vec for 600 epochs...
word2vec best epoch: 426, loss: 32120.0
Fold 6 (prep data) done in: 1.146 minutes (0.019 hours)
After sliding window: ((6778, 100, 125), (6778, 2))
After sliding window: ((0, 100, 125), (0, 2))
Model: "RatLSTM"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Input (InputLayer)           [(None, 100, 125)]        0         
_________________________________________________________________
firstLstmBlock (LSTM)        (None, 100, 512)          1306624   
_________________________________________________________________
firstLstmDropout (Dropout)   (None, 100, 512)          0         
_________________________________________________________________
secondLstmBlock (LSTM)       (None, 512)               2099200   
_________________________________________________________________
secondLstmDropout (Dropout)  (None, 512)               0         
_________________________________________________________________
Output (Dense)               (None, 2)                 1026      
=================================================================
Total params: 3,406,850
Trainable params: 3,406,850
Non-trainable params: 0
_________________________________________________________________
None
(6778, 100, 125)
(6778, 2)
(0, 100, 125)
(0, 2)
Epoch 1/50
106/106 - 49s - loss: 1349.9463
Epoch 2/50
106/106 - 49s - loss: 694.5975
Epoch 3/50
106/106 - 49s - loss: 501.9588
Epoch 4/50
106/106 - 49s - loss: 321.3211
Epoch 5/50
106/106 - 49s - loss: 234.4759
Epoch 6/50
106/106 - 49s - loss: 279.5024
Epoch 7/50
106/106 - 49s - loss: 140.8797
Epoch 8/50
106/106 - 49s - loss: 115.6215
Epoch 9/50
106/106 - 49s - loss: 108.4091
Epoch 10/50
106/106 - 49s - loss: 86.5466
Epoch 11/50
106/106 - 49s - loss: 87.9279
Epoch 12/50
106/106 - 49s - loss: 107.1499
Epoch 13/50
106/106 - 49s - loss: 70.8449
Epoch 14/50
106/106 - 49s - loss: 70.3027
Epoch 15/50
106/106 - 49s - loss: 64.3298
Epoch 16/50
106/106 - 49s - loss: 58.5820
Epoch 17/50
106/106 - 49s - loss: 59.1319
Epoch 18/50
106/106 - 49s - loss: 82.7273
Epoch 19/50
106/106 - 49s - loss: 53.0756
Epoch 20/50
106/106 - 50s - loss: 50.3749
Epoch 21/50
106/106 - 49s - loss: 47.1787
Epoch 22/50
106/106 - 49s - loss: 47.4198
Epoch 23/50
106/106 - 49s - loss: 45.8076
Epoch 24/50
106/106 - 49s - loss: 48.0070
Epoch 25/50
106/106 - 49s - loss: 44.3348
Epoch 26/50
106/106 - 49s - loss: 43.0742
Epoch 27/50
106/106 - 49s - loss: 41.3619
Epoch 28/50
106/106 - 49s - loss: 40.0684
Epoch 29/50
106/106 - 49s - loss: 41.4086
Epoch 30/50
106/106 - 49s - loss: 38.4303
Epoch 31/50
106/106 - 49s - loss: 38.4545
Epoch 32/50
106/106 - 49s - loss: 38.7385
Epoch 33/50
106/106 - 49s - loss: 38.7121
Epoch 34/50
106/106 - 49s - loss: 58.4429
Epoch 35/50
106/106 - 49s - loss: 35.7784
Epoch 36/50
106/106 - 49s - loss: 35.0427
Epoch 37/50
106/106 - 49s - loss: 34.7918
Epoch 38/50
106/106 - 49s - loss: 34.9148
Epoch 39/50
106/106 - 49s - loss: 33.8021
Epoch 40/50
106/106 - 49s - loss: 34.8579
Epoch 41/50
106/106 - 49s - loss: 32.6432
Epoch 42/50
106/106 - 49s - loss: 31.8794
Epoch 43/50
106/106 - 49s - loss: 33.2315
Epoch 44/50
106/106 - 49s - loss: 32.0357
Epoch 45/50
106/106 - 49s - loss: 31.3156
Epoch 46/50
106/106 - 49s - loss: 30.0749
Epoch 47/50
106/106 - 49s - loss: 32.7308
Epoch 48/50
106/106 - 49s - loss: 30.5491
Epoch 49/50
106/106 - 49s - loss: 30.0856
Epoch 50/50
106/106 - 49s - loss: 30.4435
After sliding window: ((673, 100, 125), (673, 2))
After sliding window: ((6848, 100, 125), (6848, 2))

Errors of models with sentences (fold= 6 ):
mean: test:  16.136252256918176 train: 5.557092791538947
median: test:  12.242401550614453 train: 4.874760047106288
Fold 6 (sents) done in: 41.945 minutes (0.699 hours)
-------------------------------------------

After sliding window: ((6778, 100, 63), (6778, 2))
After sliding window: ((0, 100, 63), (0, 2))
Model: "RatLSTM"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Input (InputLayer)           [(None, 100, 63)]         0         
_________________________________________________________________
firstLstmBlock (LSTM)        (None, 100, 512)          1179648   
_________________________________________________________________
firstLstmDropout (Dropout)   (None, 100, 512)          0         
_________________________________________________________________
secondLstmBlock (LSTM)       (None, 512)               2099200   
_________________________________________________________________
secondLstmDropout (Dropout)  (None, 512)               0         
_________________________________________________________________
Output (Dense)               (None, 2)                 1026      
=================================================================
Total params: 3,279,874
Trainable params: 3,279,874
Non-trainable params: 0
_________________________________________________________________
None
(6778, 100, 63)
(6778, 2)
(0, 100, 63)
(0, 2)
Epoch 1/50
106/106 - 49s - loss: 1546.1152
Epoch 2/50
106/106 - 49s - loss: 784.9667
Epoch 3/50
106/106 - 49s - loss: 827.8475
Epoch 4/50
106/106 - 49s - loss: 768.8229
Epoch 5/50
106/106 - 49s - loss: 772.0786
Epoch 6/50
106/106 - 49s - loss: 627.5250
Epoch 7/50
106/106 - 49s - loss: 545.7715
Epoch 8/50
106/106 - 49s - loss: 494.6549
Epoch 9/50
106/106 - 49s - loss: 389.8408
Epoch 10/50
106/106 - 49s - loss: 343.8006
Epoch 11/50
106/106 - 49s - loss: 245.6536
Epoch 12/50
106/106 - 49s - loss: 188.8639
Epoch 13/50
106/106 - 49s - loss: 146.0178
Epoch 14/50
106/106 - 49s - loss: 117.0455
Epoch 15/50
106/106 - 49s - loss: 103.5184
Epoch 16/50
106/106 - 49s - loss: 87.0807
Epoch 17/50
106/106 - 49s - loss: 84.1471
Epoch 18/50
106/106 - 49s - loss: 75.5982
Epoch 19/50
106/106 - 49s - loss: 71.4070
Epoch 20/50
106/106 - 49s - loss: 66.5779
Epoch 21/50
106/106 - 49s - loss: 62.0830
Epoch 22/50
106/106 - 49s - loss: 56.2286
Epoch 23/50
106/106 - 49s - loss: 54.6709
Epoch 24/50
106/106 - 49s - loss: 53.3550
Epoch 25/50
106/106 - 49s - loss: 49.7381
Epoch 26/50
106/106 - 49s - loss: 47.6594
Epoch 27/50
106/106 - 49s - loss: 49.6549
Epoch 28/50
106/106 - 49s - loss: 43.3295
Epoch 29/50
106/106 - 49s - loss: 44.9321
Epoch 30/50
106/106 - 49s - loss: 42.2605
Epoch 31/50
106/106 - 49s - loss: 41.6425
Epoch 32/50
106/106 - 49s - loss: 40.1408
Epoch 33/50
106/106 - 49s - loss: 39.4694
Epoch 34/50
106/106 - 49s - loss: 38.6566
Epoch 35/50
106/106 - 49s - loss: 36.8010
Epoch 36/50
106/106 - 49s - loss: 37.3226
Epoch 37/50
106/106 - 49s - loss: 37.7979
Epoch 38/50
106/106 - 49s - loss: 34.2870
Epoch 39/50
106/106 - 49s - loss: 33.6857
Epoch 40/50
106/106 - 49s - loss: 33.4180
Epoch 41/50
106/106 - 49s - loss: 34.0939
Epoch 42/50
106/106 - 49s - loss: 32.5291
Epoch 43/50
106/106 - 49s - loss: 32.2348
Epoch 44/50
106/106 - 49s - loss: 33.2493
Epoch 45/50
106/106 - 49s - loss: 32.0888
Epoch 46/50
106/106 - 49s - loss: 31.1887
Epoch 47/50
106/106 - 49s - loss: 30.7187
Epoch 48/50
106/106 - 49s - loss: 29.9353
Epoch 49/50
106/106 - 49s - loss: 29.9277
Epoch 50/50
106/106 - 49s - loss: 31.0380
After sliding window: ((673, 100, 63), (673, 2))
After sliding window: ((6848, 100, 63), (6848, 2))

Errors of models with spikes (fold= 6 ):
mean: test:  13.50347345950534 train: 5.84495062555316
median: test:  10.80413217909256 train: 5.089248296799427
Fold 6 (spikes) done in: 41.774 minutes (0.696 hours)
======================================================

FOLD =  7 :
======================================================
preparing data...
Training word2vec for 600 epochs...
word2vec best epoch: 556, loss: 32484.0
Fold 7 (prep data) done in: 1.159 minutes (0.019 hours)
After sliding window: ((6778, 100, 125), (6778, 2))
After sliding window: ((0, 100, 125), (0, 2))
Model: "RatLSTM"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Input (InputLayer)           [(None, 100, 125)]        0         
_________________________________________________________________
firstLstmBlock (LSTM)        (None, 100, 512)          1306624   
_________________________________________________________________
firstLstmDropout (Dropout)   (None, 100, 512)          0         
_________________________________________________________________
secondLstmBlock (LSTM)       (None, 512)               2099200   
_________________________________________________________________
secondLstmDropout (Dropout)  (None, 512)               0         
_________________________________________________________________
Output (Dense)               (None, 2)                 1026      
=================================================================
Total params: 3,406,850
Trainable params: 3,406,850
Non-trainable params: 0
_________________________________________________________________
None
(6778, 100, 125)
(6778, 2)
(0, 100, 125)
(0, 2)
Epoch 1/50
106/106 - 49s - loss: 1368.3658
Epoch 2/50
106/106 - 50s - loss: 812.4438
Epoch 3/50
106/106 - 49s - loss: 611.3503
Epoch 4/50
106/106 - 49s - loss: 460.1690
Epoch 5/50
106/106 - 49s - loss: 344.4825
Epoch 6/50
106/106 - 49s - loss: 251.0201
Epoch 7/50
106/106 - 49s - loss: 183.8351
Epoch 8/50
106/106 - 49s - loss: 148.5611
Epoch 9/50
106/106 - 49s - loss: 114.1071
Epoch 10/50
106/106 - 49s - loss: 99.2496
Epoch 11/50
106/106 - 49s - loss: 89.0153
Epoch 12/50
106/106 - 49s - loss: 79.1872
Epoch 13/50
106/106 - 49s - loss: 73.6484
Epoch 14/50
106/106 - 49s - loss: 69.5029
Epoch 15/50
106/106 - 49s - loss: 68.6185
Epoch 16/50
106/106 - 49s - loss: 59.8429
Epoch 17/50
106/106 - 49s - loss: 58.0929
Epoch 18/50
106/106 - 49s - loss: 55.8512
Epoch 19/50
106/106 - 49s - loss: 54.1140
Epoch 20/50
106/106 - 49s - loss: 49.2907
Epoch 21/50
106/106 - 49s - loss: 50.2442
Epoch 22/50
106/106 - 49s - loss: 49.6780
Epoch 23/50
106/106 - 49s - loss: 45.4988
Epoch 24/50
106/106 - 49s - loss: 45.7341
Epoch 25/50
106/106 - 49s - loss: 72.9552
Epoch 26/50
106/106 - 50s - loss: 43.4534
Epoch 27/50
106/106 - 49s - loss: 48.7285
Epoch 28/50
106/106 - 49s - loss: 41.0554
Epoch 29/50
106/106 - 49s - loss: 38.9127
Epoch 30/50
106/106 - 50s - loss: 41.0591
Epoch 31/50
106/106 - 49s - loss: 38.4049
Epoch 32/50
106/106 - 49s - loss: 37.4299
Epoch 33/50
106/106 - 49s - loss: 38.4621
Epoch 34/50
106/106 - 49s - loss: 36.4577
Epoch 35/50
106/106 - 49s - loss: 38.6731
Epoch 36/50
106/106 - 50s - loss: 37.7115
Epoch 37/50
106/106 - 49s - loss: 36.1659
Epoch 38/50
106/106 - 50s - loss: 34.4755
Epoch 39/50
106/106 - 51s - loss: 32.8704
Epoch 40/50
106/106 - 51s - loss: 34.9699
Epoch 41/50
106/106 - 50s - loss: 33.6355
Epoch 42/50
106/106 - 50s - loss: 32.2695
Epoch 43/50
106/106 - 50s - loss: 32.1057
Epoch 44/50
106/106 - 50s - loss: 31.9307
Epoch 45/50
106/106 - 51s - loss: 32.5489
Epoch 46/50
106/106 - 50s - loss: 32.8204
Epoch 47/50
106/106 - 51s - loss: 30.9660
Epoch 48/50
106/106 - 50s - loss: 30.3239
Epoch 49/50
106/106 - 50s - loss: 30.7296
Epoch 50/50
106/106 - 51s - loss: 29.1046
After sliding window: ((673, 100, 125), (673, 2))
After sliding window: ((6848, 100, 125), (6848, 2))

Errors of models with sentences (fold= 7 ):
mean: test:  13.570324834656358 train: 4.305025489187483
median: test:  10.345284134449544 train: 3.6626134866196303
Fold 7 (sents) done in: 42.349 minutes (0.706 hours)
-------------------------------------------

After sliding window: ((6778, 100, 63), (6778, 2))
After sliding window: ((0, 100, 63), (0, 2))
Model: "RatLSTM"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Input (InputLayer)           [(None, 100, 63)]         0         
_________________________________________________________________
firstLstmBlock (LSTM)        (None, 100, 512)          1179648   
_________________________________________________________________
firstLstmDropout (Dropout)   (None, 100, 512)          0         
_________________________________________________________________
secondLstmBlock (LSTM)       (None, 512)               2099200   
_________________________________________________________________
secondLstmDropout (Dropout)  (None, 512)               0         
_________________________________________________________________
Output (Dense)               (None, 2)                 1026      
=================================================================
Total params: 3,279,874
Trainable params: 3,279,874
Non-trainable params: 0
_________________________________________________________________
None
(6778, 100, 63)
(6778, 2)
(0, 100, 63)
(0, 2)
Epoch 1/50
106/106 - 50s - loss: 1376.3853
Epoch 2/50
106/106 - 50s - loss: 806.5908
Epoch 3/50
106/106 - 50s - loss: 873.1034
Epoch 4/50
106/106 - 50s - loss: 816.1453
Epoch 5/50
106/106 - 50s - loss: 679.7494
Epoch 6/50
106/106 - 51s - loss: 582.1638
Epoch 7/50
106/106 - 51s - loss: 452.5796
Epoch 8/50
106/106 - 51s - loss: 328.1444
Epoch 9/50
106/106 - 51s - loss: 281.1059
Epoch 10/50
106/106 - 51s - loss: 184.5035
Epoch 11/50
106/106 - 51s - loss: 152.8467
Epoch 12/50
106/106 - 51s - loss: 115.3000
Epoch 13/50
106/106 - 51s - loss: 97.2745
Epoch 14/50
106/106 - 51s - loss: 89.2712
Epoch 15/50
106/106 - 51s - loss: 78.2977
Epoch 16/50
106/106 - 51s - loss: 72.4435
Epoch 17/50
106/106 - 51s - loss: 69.9244
Epoch 18/50
106/106 - 51s - loss: 64.5493
Epoch 19/50
106/106 - 51s - loss: 58.2842
Epoch 20/50
106/106 - 51s - loss: 55.0664
Epoch 21/50
106/106 - 51s - loss: 54.3467
Epoch 22/50
106/106 - 51s - loss: 49.6604
Epoch 23/50
106/106 - 51s - loss: 49.0819
Epoch 24/50
106/106 - 51s - loss: 47.7769
Epoch 25/50
106/106 - 49s - loss: 46.4953
Epoch 26/50
106/106 - 49s - loss: 45.0411
Epoch 27/50
106/106 - 50s - loss: 43.2856
Epoch 28/50
106/106 - 50s - loss: 42.2028
Epoch 29/50
106/106 - 49s - loss: 41.5667
Epoch 30/50
106/106 - 51s - loss: 41.5735
Epoch 31/50
106/106 - 52s - loss: 39.8492
Epoch 32/50
106/106 - 52s - loss: 40.3487
Epoch 33/50
106/106 - 52s - loss: 35.9852
Epoch 34/50
106/106 - 51s - loss: 35.9645
Epoch 35/50
106/106 - 51s - loss: 34.1394
Epoch 36/50
106/106 - 51s - loss: 34.9140
Epoch 37/50
106/106 - 52s - loss: 35.4965
Epoch 38/50
106/106 - 52s - loss: 33.6589
Epoch 39/50
106/106 - 51s - loss: 33.3146
Epoch 40/50
106/106 - 52s - loss: 31.8813
Epoch 41/50
106/106 - 52s - loss: 31.4801
Epoch 42/50
106/106 - 52s - loss: 33.2199
Epoch 43/50
106/106 - 53s - loss: 31.1728
Epoch 44/50
106/106 - 52s - loss: 30.8918
Epoch 45/50
106/106 - 53s - loss: 31.2322
Epoch 46/50
106/106 - 53s - loss: 30.4949
Epoch 47/50
106/106 - 54s - loss: 30.5130
Epoch 48/50
106/106 - 53s - loss: 30.3069
Epoch 49/50
106/106 - 52s - loss: 29.5945
Epoch 50/50
106/106 - 53s - loss: 28.7180
After sliding window: ((673, 100, 63), (673, 2))
After sliding window: ((6848, 100, 63), (6848, 2))

Errors of models with spikes (fold= 7 ):
mean: test:  10.398437117926088 train: 3.6009211247573796
median: test:  9.15157205183349 train: 3.1620742587935626
Fold 7 (spikes) done in: 43.788 minutes (0.73 hours)
======================================================

FOLD =  8 :
======================================================
preparing data...
Training word2vec for 600 epochs...
word2vec best epoch: 408, loss: 31524.0
Fold 8 (prep data) done in: 1.751 minutes (0.029 hours)
After sliding window: ((6778, 100, 125), (6778, 2))
After sliding window: ((0, 100, 125), (0, 2))
Model: "RatLSTM"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Input (InputLayer)           [(None, 100, 125)]        0         
_________________________________________________________________
firstLstmBlock (LSTM)        (None, 100, 512)          1306624   
_________________________________________________________________
firstLstmDropout (Dropout)   (None, 100, 512)          0         
_________________________________________________________________
secondLstmBlock (LSTM)       (None, 512)               2099200   
_________________________________________________________________
secondLstmDropout (Dropout)  (None, 512)               0         
_________________________________________________________________
Output (Dense)               (None, 2)                 1026      
=================================================================
Total params: 3,406,850
Trainable params: 3,406,850
Non-trainable params: 0
_________________________________________________________________
None
(6778, 100, 125)
(6778, 2)
(0, 100, 125)
(0, 2)
Epoch 1/50
106/106 - 56s - loss: 1402.5105
Epoch 2/50
106/106 - 56s - loss: 804.7015
Epoch 3/50
106/106 - 56s - loss: 606.9967
Epoch 4/50
106/106 - 52s - loss: 416.1664
Epoch 5/50
106/106 - 52s - loss: 279.6546
Epoch 6/50
106/106 - 52s - loss: 189.3841
Epoch 7/50
106/106 - 52s - loss: 145.5695
Epoch 8/50
106/106 - 51s - loss: 127.0771
Epoch 9/50
106/106 - 51s - loss: 107.7125
Epoch 10/50
106/106 - 51s - loss: 89.7567
Epoch 11/50
106/106 - 51s - loss: 87.8250
Epoch 12/50
106/106 - 52s - loss: 76.6562
Epoch 13/50
106/106 - 51s - loss: 71.3307
Epoch 14/50
106/106 - 51s - loss: 66.7878
Epoch 15/50
106/106 - 50s - loss: 64.3576
Epoch 16/50
106/106 - 51s - loss: 75.3267
Epoch 17/50
106/106 - 51s - loss: 62.4612
Epoch 18/50
106/106 - 50s - loss: 53.9597
Epoch 19/50
106/106 - 51s - loss: 50.0601
Epoch 20/50
106/106 - 51s - loss: 50.1066
Epoch 21/50
106/106 - 51s - loss: 49.3086
Epoch 22/50
106/106 - 52s - loss: 46.9319
Epoch 23/50
106/106 - 51s - loss: 48.0220
Epoch 24/50
106/106 - 51s - loss: 45.0267
Epoch 25/50
106/106 - 51s - loss: 43.0307
Epoch 26/50
106/106 - 50s - loss: 43.2775
Epoch 27/50
106/106 - 50s - loss: 40.7796
Epoch 28/50
106/106 - 50s - loss: 39.4888
Epoch 29/50
106/106 - 49s - loss: 38.4368
Epoch 30/50
106/106 - 49s - loss: 38.6635
Epoch 31/50
106/106 - 49s - loss: 39.2539
Epoch 32/50
106/106 - 50s - loss: 39.2448
Epoch 33/50
106/106 - 49s - loss: 36.2052
Epoch 34/50
106/106 - 50s - loss: 37.1949
Epoch 35/50
106/106 - 50s - loss: 35.1652
Epoch 36/50
106/106 - 50s - loss: 34.2328
Epoch 37/50
106/106 - 49s - loss: 33.9598
Epoch 38/50
106/106 - 49s - loss: 33.9353
Epoch 39/50
106/106 - 50s - loss: 37.0981
Epoch 40/50
106/106 - 50s - loss: 31.8208
Epoch 41/50
106/106 - 49s - loss: 32.8917
Epoch 42/50
106/106 - 49s - loss: 31.9538
Epoch 43/50
106/106 - 49s - loss: 32.7708
Epoch 44/50
106/106 - 49s - loss: 31.4653
Epoch 45/50
106/106 - 49s - loss: 31.4308
Epoch 46/50
106/106 - 50s - loss: 31.1158
Epoch 47/50
106/106 - 50s - loss: 31.0867
Epoch 48/50
106/106 - 50s - loss: 30.2989
Epoch 49/50
106/106 - 50s - loss: 30.9397
Epoch 50/50
106/106 - 49s - loss: 30.4129
After sliding window: ((673, 100, 125), (673, 2))
After sliding window: ((6848, 100, 125), (6848, 2))

Errors of models with sentences (fold= 8 ):
mean: test:  17.173858141862397 train: 4.295448756123921
median: test:  13.599687205287472 train: 3.733205388451736
Fold 8 (sents) done in: 43.226 minutes (0.72 hours)
-------------------------------------------

After sliding window: ((6778, 100, 63), (6778, 2))
After sliding window: ((0, 100, 63), (0, 2))
Model: "RatLSTM"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Input (InputLayer)           [(None, 100, 63)]         0         
_________________________________________________________________
firstLstmBlock (LSTM)        (None, 100, 512)          1179648   
_________________________________________________________________
firstLstmDropout (Dropout)   (None, 100, 512)          0         
_________________________________________________________________
secondLstmBlock (LSTM)       (None, 512)               2099200   
_________________________________________________________________
secondLstmDropout (Dropout)  (None, 512)               0         
_________________________________________________________________
Output (Dense)               (None, 2)                 1026      
=================================================================
Total params: 3,279,874
Trainable params: 3,279,874
Non-trainable params: 0
_________________________________________________________________
None
(6778, 100, 63)
(6778, 2)
(0, 100, 63)
(0, 2)
Epoch 1/50
106/106 - 49s - loss: 1383.2959
Epoch 2/50
106/106 - 49s - loss: 843.5152
Epoch 3/50
106/106 - 49s - loss: 823.5356
Epoch 4/50
106/106 - 49s - loss: 789.9482
Epoch 5/50
106/106 - 49s - loss: 721.0370
Epoch 6/50
106/106 - 49s - loss: 584.0875
Epoch 7/50
106/106 - 49s - loss: 461.0557
Epoch 8/50
106/106 - 49s - loss: 325.3559
Epoch 9/50
106/106 - 49s - loss: 253.9305
Epoch 10/50
106/106 - 49s - loss: 177.2560
Epoch 11/50
106/106 - 49s - loss: 162.2364
Epoch 12/50
106/106 - 49s - loss: 113.4918
Epoch 13/50
106/106 - 49s - loss: 95.6916
Epoch 14/50
106/106 - 49s - loss: 93.6186
Epoch 15/50
106/106 - 49s - loss: 80.1349
Epoch 16/50
106/106 - 49s - loss: 71.2758
Epoch 17/50
106/106 - 49s - loss: 66.7640
Epoch 18/50
106/106 - 49s - loss: 59.9305
Epoch 19/50
106/106 - 49s - loss: 60.9888
Epoch 20/50
106/106 - 49s - loss: 74.7091
Epoch 21/50
106/106 - 49s - loss: 51.8891
Epoch 22/50
106/106 - 49s - loss: 48.5870
Epoch 23/50
106/106 - 49s - loss: 51.0702
Epoch 24/50
106/106 - 49s - loss: 44.8803
Epoch 25/50
106/106 - 49s - loss: 46.3193
Epoch 26/50
106/106 - 49s - loss: 43.3312
Epoch 27/50
106/106 - 49s - loss: 41.4204
Epoch 28/50
106/106 - 49s - loss: 41.8651
Epoch 29/50
106/106 - 49s - loss: 39.2247
Epoch 30/50
106/106 - 49s - loss: 40.3285
Epoch 31/50
106/106 - 49s - loss: 38.4661
Epoch 32/50
106/106 - 49s - loss: 37.9909
Epoch 33/50
106/106 - 49s - loss: 42.7462
Epoch 34/50
106/106 - 49s - loss: 34.7334
Epoch 35/50
106/106 - 49s - loss: 36.4220
Epoch 36/50
106/106 - 49s - loss: 35.1422
Epoch 37/50
106/106 - 49s - loss: 33.7086
Epoch 38/50
106/106 - 49s - loss: 34.9389
Epoch 39/50
106/106 - 49s - loss: 33.6576
Epoch 40/50
106/106 - 49s - loss: 31.5243
Epoch 41/50
106/106 - 49s - loss: 32.4634
Epoch 42/50
106/106 - 49s - loss: 31.7307
Epoch 43/50
106/106 - 49s - loss: 30.5464
Epoch 44/50
106/106 - 49s - loss: 30.6966
Epoch 45/50
106/106 - 49s - loss: 30.6221
Epoch 46/50
106/106 - 49s - loss: 30.4544
Epoch 47/50
106/106 - 49s - loss: 30.0813
Epoch 48/50
106/106 - 49s - loss: 30.1998
Epoch 49/50
106/106 - 49s - loss: 29.1037
Epoch 50/50
106/106 - 49s - loss: 28.7000
After sliding window: ((673, 100, 63), (673, 2))
After sliding window: ((6848, 100, 63), (6848, 2))

Errors of models with spikes (fold= 8 ):
mean: test:  11.413051414189015 train: 4.081848835551575
median: test:  9.12491242627686 train: 3.602253752353339
Fold 8 (spikes) done in: 41.859 minutes (0.698 hours)
======================================================

FOLD =  9 :
======================================================
preparing data...
Training word2vec for 600 epochs...
word2vec best epoch: 563, loss: 31770.0
Fold 9 (prep data) done in: 1.164 minutes (0.019 hours)
After sliding window: ((6778, 100, 125), (6778, 2))
After sliding window: ((0, 100, 125), (0, 2))
Model: "RatLSTM"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Input (InputLayer)           [(None, 100, 125)]        0         
_________________________________________________________________
firstLstmBlock (LSTM)        (None, 100, 512)          1306624   
_________________________________________________________________
firstLstmDropout (Dropout)   (None, 100, 512)          0         
_________________________________________________________________
secondLstmBlock (LSTM)       (None, 512)               2099200   
_________________________________________________________________
secondLstmDropout (Dropout)  (None, 512)               0         
_________________________________________________________________
Output (Dense)               (None, 2)                 1026      
=================================================================
Total params: 3,406,850
Trainable params: 3,406,850
Non-trainable params: 0
_________________________________________________________________
None
(6778, 100, 125)
(6778, 2)
(0, 100, 125)
(0, 2)
Epoch 1/50
106/106 - 49s - loss: 1301.4596
Epoch 2/50
106/106 - 49s - loss: 798.0966
Epoch 3/50
106/106 - 49s - loss: 532.5305
Epoch 4/50
106/106 - 49s - loss: 370.9949
Epoch 5/50
106/106 - 49s - loss: 257.6237
Epoch 6/50
106/106 - 49s - loss: 197.9966
Epoch 7/50
106/106 - 49s - loss: 156.5663
Epoch 8/50
106/106 - 49s - loss: 121.1975
Epoch 9/50
106/106 - 49s - loss: 109.3409
Epoch 10/50
106/106 - 49s - loss: 95.6103
Epoch 11/50
106/106 - 49s - loss: 95.4293
Epoch 12/50
106/106 - 49s - loss: 85.7880
Epoch 13/50
106/106 - 49s - loss: 75.0989
Epoch 14/50
106/106 - 49s - loss: 70.9239
Epoch 15/50
106/106 - 49s - loss: 64.0931
Epoch 16/50
106/106 - 49s - loss: 60.9193
Epoch 17/50
106/106 - 49s - loss: 60.1700
Epoch 18/50
106/106 - 49s - loss: 73.2305
Epoch 19/50
106/106 - 49s - loss: 51.8589
Epoch 20/50
106/106 - 49s - loss: 51.6988
Epoch 21/50
106/106 - 49s - loss: 49.2885
Epoch 22/50
106/106 - 49s - loss: 49.4355
Epoch 23/50
106/106 - 49s - loss: 46.0812
Epoch 24/50
106/106 - 49s - loss: 49.0175
Epoch 25/50
106/106 - 49s - loss: 43.8742
Epoch 26/50
106/106 - 49s - loss: 44.3920
Epoch 27/50
106/106 - 49s - loss: 42.0278
Epoch 28/50
106/106 - 49s - loss: 40.8564
Epoch 29/50
106/106 - 49s - loss: 40.9667
Epoch 30/50
106/106 - 49s - loss: 40.4929
Epoch 31/50
106/106 - 49s - loss: 39.0737
Epoch 32/50
106/106 - 49s - loss: 37.8549
Epoch 33/50
106/106 - 49s - loss: 38.2388
Epoch 34/50
106/106 - 49s - loss: 36.6702
Epoch 35/50
106/106 - 49s - loss: 36.2428
Epoch 36/50
106/106 - 49s - loss: 63.1015
Epoch 37/50
106/106 - 49s - loss: 35.3145
Epoch 38/50
106/106 - 49s - loss: 35.6190
Epoch 39/50
106/106 - 49s - loss: 34.6812
Epoch 40/50
106/106 - 49s - loss: 34.6054
Epoch 41/50
106/106 - 49s - loss: 32.5321
Epoch 42/50
106/106 - 49s - loss: 32.3044
Epoch 43/50
106/106 - 49s - loss: 33.1030
Epoch 44/50
106/106 - 49s - loss: 32.1172
Epoch 45/50
106/106 - 49s - loss: 32.1713
Epoch 46/50
106/106 - 49s - loss: 35.2132
Epoch 47/50
106/106 - 51s - loss: 30.5992
Epoch 48/50
106/106 - 51s - loss: 32.1520
Epoch 49/50
106/106 - 51s - loss: 31.3511
Epoch 50/50
106/106 - 51s - loss: 30.7518
After sliding window: ((673, 100, 125), (673, 2))
After sliding window: ((6848, 100, 125), (6848, 2))

Errors of models with sentences (fold= 9 ):
mean: test:  12.72188920466976 train: 4.257654809379598
median: test:  11.48118266100425 train: 3.6915673892005465
Fold 9 (sents) done in: 42.054 minutes (0.701 hours)
-------------------------------------------

After sliding window: ((6778, 100, 63), (6778, 2))
After sliding window: ((0, 100, 63), (0, 2))
Model: "RatLSTM"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Input (InputLayer)           [(None, 100, 63)]         0         
_________________________________________________________________
firstLstmBlock (LSTM)        (None, 100, 512)          1179648   
_________________________________________________________________
firstLstmDropout (Dropout)   (None, 100, 512)          0         
_________________________________________________________________
secondLstmBlock (LSTM)       (None, 512)               2099200   
_________________________________________________________________
secondLstmDropout (Dropout)  (None, 512)               0         
_________________________________________________________________
Output (Dense)               (None, 2)                 1026      
=================================================================
Total params: 3,279,874
Trainable params: 3,279,874
Non-trainable params: 0
_________________________________________________________________
None
(6778, 100, 63)
(6778, 2)
(0, 100, 63)
(0, 2)
Epoch 1/50
106/106 - 52s - loss: 1453.7557
Epoch 2/50
106/106 - 50s - loss: 904.1284
Epoch 3/50
106/106 - 50s - loss: 763.2847
Epoch 4/50
106/106 - 50s - loss: 638.8048
Epoch 5/50
106/106 - 50s - loss: 480.2663
Epoch 6/50
106/106 - 50s - loss: 345.8875
Epoch 7/50
106/106 - 50s - loss: 229.6234
Epoch 8/50
106/106 - 50s - loss: 168.2414
Epoch 9/50
106/106 - 50s - loss: 135.7562
Epoch 10/50
106/106 - 50s - loss: 104.0037
Epoch 11/50
106/106 - 50s - loss: 100.9844
Epoch 12/50
106/106 - 50s - loss: 93.0964
Epoch 13/50
106/106 - 50s - loss: 88.0420
Epoch 14/50
106/106 - 50s - loss: 71.4599
Epoch 15/50
106/106 - 50s - loss: 60.6291
Epoch 16/50
106/106 - 50s - loss: 57.9619
Epoch 17/50
106/106 - 50s - loss: 54.1154
Epoch 18/50
106/106 - 50s - loss: 63.1420
Epoch 19/50
106/106 - 50s - loss: 48.1034
Epoch 20/50
106/106 - 50s - loss: 49.3871
Epoch 21/50
106/106 - 50s - loss: 45.5500
Epoch 22/50
106/106 - 50s - loss: 44.3793
Epoch 23/50
106/106 - 50s - loss: 44.3870
Epoch 24/50
106/106 - 50s - loss: 41.4598
Epoch 25/50
106/106 - 50s - loss: 45.4626
Epoch 26/50
106/106 - 50s - loss: 38.3217
Epoch 27/50
106/106 - 50s - loss: 37.1852
Epoch 28/50
106/106 - 50s - loss: 37.7131
Epoch 29/50
106/106 - 50s - loss: 35.6363
Epoch 30/50
106/106 - 50s - loss: 36.2094
Epoch 31/50
106/106 - 50s - loss: 33.9621
Epoch 32/50
106/106 - 50s - loss: 33.6331
Epoch 33/50
106/106 - 50s - loss: 33.2441
Epoch 34/50
106/106 - 50s - loss: 33.2628
Epoch 35/50
106/106 - 50s - loss: 31.4538
Epoch 36/50
106/106 - 51s - loss: 32.7896
Epoch 37/50
106/106 - 50s - loss: 31.0895
Epoch 38/50
106/106 - 50s - loss: 30.9065
Epoch 39/50
106/106 - 50s - loss: 32.2797
Epoch 40/50
106/106 - 50s - loss: 35.5680
Epoch 41/50
106/106 - 50s - loss: 27.9762
Epoch 42/50
106/106 - 50s - loss: 29.6868
Epoch 43/50
106/106 - 50s - loss: 29.8430
Epoch 44/50
106/106 - 51s - loss: 29.6316
Epoch 45/50
106/106 - 50s - loss: 28.8291
Epoch 46/50
106/106 - 51s - loss: 28.3682
Epoch 47/50
106/106 - 50s - loss: 27.9583
Epoch 48/50
106/106 - 50s - loss: 27.2297
Epoch 49/50
106/106 - 50s - loss: 27.6659
Epoch 50/50
106/106 - 50s - loss: 27.9213
After sliding window: ((673, 100, 63), (673, 2))
After sliding window: ((6848, 100, 63), (6848, 2))

Errors of models with spikes (fold= 9 ):
mean: test:  14.709536749164544 train: 3.7895445478946352
median: test:  12.663802748670525 train: 3.28979088008046
Fold 9 (spikes) done in: 42.834 minutes (0.714 hours)

------------------------------------
FINAL RESULTS:

MEAN DISTANCES IN TEST SET (cm):
   LSTM_spikes  LSTM_sents
0    13.244795   16.153242
1    13.941028   14.329326
2    11.532165   12.922017
3    13.783045   14.501966
4    10.349395   12.412447
5    11.693117   11.276448
6    13.503473   16.136252
7    10.398437   13.570325
8    11.413051   17.173858
9    14.709537   12.721889

MEDIAN DISTANCES IN TEST SET (cm):
   LSTM_spikes  LSTM_sents
0    10.550508   11.623804
1    11.977065   11.334339
2     8.868530   10.184707
3    12.521966   12.586004
4     8.560887   10.166089
5     9.522757    9.239065
6    10.804132   12.242402
7     9.151572   10.345284
8     9.124912   13.599687
9    12.663803   11.481183

Avgerages over 10 folds:
             Mean error  Median error  st.dev. of mean  st.dev of median
LSTM_spikes   12.456804     10.374613         1.481848          1.482428
LSTM_sents    14.119777     11.280256         1.800240          1.251160
